{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKgz_Cdjs98R"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsNlAvTeVGDF"
   },
   "outputs": [],
   "source": [
    "# # Colab 환경설정\n",
    "\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install mxnet\n",
    "!pip install sentencepiece==0.1.91\n",
    "!pip install transformers==4.8.2\n",
    "!pip install torch==1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "neJQAfJ8VkNn"
   },
   "outputs": [],
   "source": [
    "# # github에서 Kobert 파일 로드 및 Kobert 모델 불러오기\n",
    "\n",
    "# #kobert_tokenizer 폴더 다운받는 코드\n",
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "\n",
    "# #https://github.com/SKTBrain/KoBERT 의 파일들을 다운받는 코드\n",
    "# !pip install 'git+https://git@github.com/SKTBrain/KoBERT.git@master'\n",
    "\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import BertModel\n",
    "import gluonnlp as nlp\n",
    "\n",
    "model_name = \"skt/kobert-base-v1\"\n",
    "tokenizer = KoBERTTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "bertmodel = BertModel.from_pretrained(model_name)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7YElfQ0SXgMb"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "#GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bbrj2SPKZ254"
   },
   "outputs": [],
   "source": [
    "# 입력 데이터셋을 토큰화하기\n",
    "\n",
    "# 각 데이터가 BERT 모델의 입력으로 들어갈 수 있도록 tokenization, int encoding padding 등을 해주는 코드이다.\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer,vocab, max_len,\n",
    "                 pad, pair):\n",
    "   \n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        \n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "         \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "D1Xqo85qajit"
   },
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# target = df['Emotion']\n",
    "# # train_test_split\n",
    "# df_train, df_val = train_test_split(df, test_size=0.2, shuffle=True, stratify=target, random_state=34)\n",
    "# df_train.reset_index(drop=True, inplace=True)\n",
    "# df_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"./dataset/new_train_all.csv\", encoding=\"utf-8-sig\", index=False)\n",
    "# df_val.to_csv(\"./dataset/new_validation_all.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./dataset/new_train_all.csv\", encoding='utf-8')\n",
    "df_val = pd.read_csv(\"./dataset/new_validation_all.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3주 정도 된 것 같아</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>걱정할 것 같아서 얘기를 못 하겠어</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지금은 많이 좋아졌어 하지만 또 천둥 칠까봐 무섭긴 해</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>너무 마음에 들어</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비싼 향수를 당첨 선물로 받았다고 주위 사람들한테 자랑했어 다들 부러워 하더라고</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31896</th>\n",
       "      <td>조언해줘서 고마워</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31897</th>\n",
       "      <td>맞아 밖에 나가서 햇빛 좀 받으면서 활동해야 한다고</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31898</th>\n",
       "      <td>친구랑 약속 있어 나왔는데 친구가 아직도 오질 않고 있어</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31899</th>\n",
       "      <td>좋은 곳으로 갔을 거야 내 말 들어줘서 고마워</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31900</th>\n",
       "      <td>그러면 좋지 나도 고민 안해도 되고 여기저기 찾아보지 않아도 괜찮으니까</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31901 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                발화문    Emotion\n",
       "0                                      3주 정도 된 것 같아    neutral\n",
       "1                               걱정할 것 같아서 얘기를 못 하겠어    sadness\n",
       "2                    지금은 많이 좋아졌어 하지만 또 천둥 칠까봐 무섭긴 해       fear\n",
       "3                                         너무 마음에 들어  happiness\n",
       "4      비싼 향수를 당첨 선물로 받았다고 주위 사람들한테 자랑했어 다들 부러워 하더라고    neutral\n",
       "...                                             ...        ...\n",
       "31896                                     조언해줘서 고마워  happiness\n",
       "31897                  맞아 밖에 나가서 햇빛 좀 받으면서 활동해야 한다고    neutral\n",
       "31898               친구랑 약속 있어 나왔는데 친구가 아직도 오질 않고 있어      angry\n",
       "31899                     좋은 곳으로 갔을 거야 내 말 들어줘서 고마워  happiness\n",
       "31900       그러면 좋지 나도 고민 안해도 되고 여기저기 찾아보지 않아도 괜찮으니까  happiness\n",
       "\n",
       "[31901 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나 결국 남자친구랑 헤어졌어</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네 그래야될 거 같아요 손해가 너무 많아가지고</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>집에서 나올 때 우산 챙겨오면 돼 걱정하지 마 건강은 괜찮지</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어 그거 괜찮은 생각이다 좋은 조언해줘서 고마워</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그러게 안그래도 더 그런 것 같다 장마 때문에 아 진짜 어떡하지</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>응 지금은 조금 진정됐어 근데 어젯밤에는 너무너무 깜짝놀래서 진짜 놀랬지 뭐야</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>퇴근한 지 얼마나 됐다고 회사에서 또 전화가 왔어</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>내가 재빠르게 달려가서 해피를 안고 와서 아무일도 없었어 다행이었어</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>지금 30분 넘었어</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>그래 그래야겠다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7976 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              발화문    Emotion\n",
       "0                                 나 결국 남자친구랑 헤어졌어    neutral\n",
       "1                       네 그래야될 거 같아요 손해가 너무 많아가지고    sadness\n",
       "2               집에서 나올 때 우산 챙겨오면 돼 걱정하지 마 건강은 괜찮지    neutral\n",
       "3                      어 그거 괜찮은 생각이다 좋은 조언해줘서 고마워  happiness\n",
       "4             그러게 안그래도 더 그런 것 같다 장마 때문에 아 진짜 어떡하지      angry\n",
       "...                                           ...        ...\n",
       "7971  응 지금은 조금 진정됐어 근데 어젯밤에는 너무너무 깜짝놀래서 진짜 놀랬지 뭐야    neutral\n",
       "7972                  퇴근한 지 얼마나 됐다고 회사에서 또 전화가 왔어    neutral\n",
       "7973        내가 재빠르게 달려가서 해피를 안고 와서 아무일도 없었어 다행이었어  happiness\n",
       "7974                                   지금 30분 넘었어    neutral\n",
       "7975                                     그래 그래야겠다    neutral\n",
       "\n",
       "[7976 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.replace({\"Emotion\":{\"neutral\": 0, \"happiness\": 1, \"sadness\": 2, \"angry\": 3, \"disgust\": 4, \"fear\": 5, \"surprise\": 6}})\n",
    "df_val = df_val.replace({\"Emotion\":{\"neutral\": 0, \"happiness\": 1, \"sadness\": 2, \"angry\": 3, \"disgust\": 4, \"fear\": 5, \"surprise\": 6}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3주 정도 된 것 같아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>걱정할 것 같아서 얘기를 못 하겠어</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지금은 많이 좋아졌어 하지만 또 천둥 칠까봐 무섭긴 해</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>너무 마음에 들어</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비싼 향수를 당첨 선물로 받았다고 주위 사람들한테 자랑했어 다들 부러워 하더라고</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31896</th>\n",
       "      <td>조언해줘서 고마워</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31897</th>\n",
       "      <td>맞아 밖에 나가서 햇빛 좀 받으면서 활동해야 한다고</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31898</th>\n",
       "      <td>친구랑 약속 있어 나왔는데 친구가 아직도 오질 않고 있어</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31899</th>\n",
       "      <td>좋은 곳으로 갔을 거야 내 말 들어줘서 고마워</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31900</th>\n",
       "      <td>그러면 좋지 나도 고민 안해도 되고 여기저기 찾아보지 않아도 괜찮으니까</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31901 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                발화문  Emotion\n",
       "0                                      3주 정도 된 것 같아        0\n",
       "1                               걱정할 것 같아서 얘기를 못 하겠어        2\n",
       "2                    지금은 많이 좋아졌어 하지만 또 천둥 칠까봐 무섭긴 해        5\n",
       "3                                         너무 마음에 들어        1\n",
       "4      비싼 향수를 당첨 선물로 받았다고 주위 사람들한테 자랑했어 다들 부러워 하더라고        0\n",
       "...                                             ...      ...\n",
       "31896                                     조언해줘서 고마워        1\n",
       "31897                  맞아 밖에 나가서 햇빛 좀 받으면서 활동해야 한다고        0\n",
       "31898               친구랑 약속 있어 나왔는데 친구가 아직도 오질 않고 있어        3\n",
       "31899                     좋은 곳으로 갔을 거야 내 말 들어줘서 고마워        1\n",
       "31900       그러면 좋지 나도 고민 안해도 되고 여기저기 찾아보지 않아도 괜찮으니까        1\n",
       "\n",
       "[31901 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나 결국 남자친구랑 헤어졌어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네 그래야될 거 같아요 손해가 너무 많아가지고</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>집에서 나올 때 우산 챙겨오면 돼 걱정하지 마 건강은 괜찮지</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어 그거 괜찮은 생각이다 좋은 조언해줘서 고마워</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그러게 안그래도 더 그런 것 같다 장마 때문에 아 진짜 어떡하지</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>응 지금은 조금 진정됐어 근데 어젯밤에는 너무너무 깜짝놀래서 진짜 놀랬지 뭐야</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>퇴근한 지 얼마나 됐다고 회사에서 또 전화가 왔어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>내가 재빠르게 달려가서 해피를 안고 와서 아무일도 없었어 다행이었어</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>지금 30분 넘었어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>그래 그래야겠다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7976 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              발화문  Emotion\n",
       "0                                 나 결국 남자친구랑 헤어졌어        0\n",
       "1                       네 그래야될 거 같아요 손해가 너무 많아가지고        2\n",
       "2               집에서 나올 때 우산 챙겨오면 돼 걱정하지 마 건강은 괜찮지        0\n",
       "3                      어 그거 괜찮은 생각이다 좋은 조언해줘서 고마워        1\n",
       "4             그러게 안그래도 더 그런 것 같다 장마 때문에 아 진짜 어떡하지        3\n",
       "...                                           ...      ...\n",
       "7971  응 지금은 조금 진정됐어 근데 어젯밤에는 너무너무 깜짝놀래서 진짜 놀랬지 뭐야        0\n",
       "7972                  퇴근한 지 얼마나 됐다고 회사에서 또 전화가 왔어        0\n",
       "7973        내가 재빠르게 달려가서 해피를 안고 와서 아무일도 없었어 다행이었어        1\n",
       "7974                                   지금 30분 넘었어        0\n",
       "7975                                     그래 그래야겠다        0\n",
       "\n",
       "[7976 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.363591\n",
       "2    0.241976\n",
       "3    0.150702\n",
       "1    0.125502\n",
       "4    0.052533\n",
       "5    0.051153\n",
       "6    0.014544\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['Emotion'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 5, 4, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = []\n",
    "for ques, label in zip(df_train['발화문'], df_train['Emotion']):\n",
    "    data = []\n",
    "    data.append(ques)\n",
    "    data.append(label)\n",
    "    \n",
    "    dataset_train.append(data)\n",
    "    \n",
    "dataset_val = []\n",
    "for ques, label in zip(df_val['발화문'], df_val['Emotion']):\n",
    "    data = []\n",
    "    data.append(ques)\n",
    "    data.append(label)\n",
    "    \n",
    "    dataset_val.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "MetYxxwmaqoi"
   },
   "outputs": [],
   "source": [
    "tok=tokenizer.tokenize\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, vocab, max_len, True, False)\n",
    "data_validation = BERTDataset(dataset_val,0, 1, tok, vocab,  max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "OtuLeIMVatqv"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=0)\n",
    "validation_dataloader = torch.utils.data.DataLoader(data_validation, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "7NNpyy9Lavfz"
   },
   "outputs": [],
   "source": [
    "# KoBERT 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "IhcQgX__az28"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11597\n",
       "2     7720\n",
       "3     4806\n",
       "1     4003\n",
       "4     1675\n",
       "5     1633\n",
       "6      467\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "gmIBAo5-puy9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f4a55b8e190>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    " \n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 대표적인 loss func\n",
    "\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    \n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차행렬, 정확도, 정밀도, 재현율 f1 score을 한번에 출력하기 위한 함수 정의\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_eval(y_true, y_pred):\n",
    "#     confusion = confusion_matrix(y_test, pred)\n",
    "#     answer = torch.cat(y_test).detach().cpu().tolist()\n",
    "#     temp = torch.cat(pred).detach().cpu().tolist()\n",
    "#     prediction = []\n",
    "#     for i in range(len(temp)):\n",
    "#         prediction.append(temp[i].index(max(temp[i])))\n",
    "    answer = y_true\n",
    "    prediction = y_pred\n",
    "    accuracy = accuracy_score(answer, prediction)\n",
    "    precision = precision_score(answer, prediction, average= \"weighted\")\n",
    "    recall = recall_score(answer, prediction, average= \"weighted\")\n",
    "    f1 = f1_score(answer, prediction, average= \"weighted\")\n",
    "#     print('Confusion Matrix')\n",
    "#     print(confusion)\n",
    "    print('정확도:{}, 정밀도:{}, 재현율:{} f1 score:{}'.format(accuracy, precision, recall, f1))\n",
    "    text = '정확도:{}, 정밀도:{}, 재현율:{} f1 score:{}'.format(accuracy, precision, recall, f1)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31901\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 저장할 폴더 생성\n",
    "import os\n",
    "PATH = f'./Model/batch size={batch_size}, learning rate={learning_rate}/'\n",
    "os.mkdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "SKbHee64a3tn"
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3d6278ba714520a15a90d90e220fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.9512392282485962 train acc 0.15625\n",
      "epoch 1 batch id 201 loss 1.21956205368042 train acc 0.40220771144278605\n",
      "epoch 1 batch id 401 loss 0.74610835313797 train acc 0.5559149002493765\n",
      "epoch 1 train acc 0.5960001253879189\n",
      "\n",
      "Epoch 1 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab3a1c8d13945149c110d0edfee3a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.6275519132614136 validation acc 0.796875\n",
      "epoch 1 validation acc 0.7917502507522568 \n",
      "정확도:0.7917502507522568, 정밀도:0.79354697515032, 재현율:0.7917502507522568 f1 score:0.7895298290951073\n",
      "Epoch 2 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de356622cca45099d85b531c1375c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.496120810508728 train acc 0.5964648834662912\n",
      "epoch 2 batch id 201 loss 0.7178069949150085 train acc 0.6516251535798057\n",
      "epoch 2 batch id 401 loss 0.44598767161369324 train acc 0.6881785807348215\n",
      "epoch 2 train acc 0.7026738973699884\n",
      "\n",
      "Epoch 2 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd83987b25b4954b787d9344aa16ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.49628201127052307 validation acc 0.7924129353233831\n",
      "epoch 2 validation acc 0.8081745235707122 \n",
      "정확도:0.8081745235707122, 정밀도:0.8099760168664657, 재현율:0.8081745235707122 f1 score:0.8067514817973648\n",
      "Epoch 3 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477f0b297db7412ea2e27acd758cfa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.328411340713501 train acc 0.7028622428209063\n",
      "epoch 3 batch id 201 loss 0.49395284056663513 train acc 0.7284063339681215\n",
      "epoch 3 batch id 401 loss 0.2526352107524872 train acc 0.7486531196208616\n",
      "epoch 3 train acc 0.7575520098638496\n",
      "\n",
      "Epoch 3 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a41a83c5124b1285d918a72f05037d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.42651134729385376 validation acc 0.8084415584415584\n",
      "epoch 3 validation acc 0.8182046138415245 \n",
      "정확도:0.8182046138415245, 정밀도:0.8194927907790366, 재현율:0.8182046138415245 f1 score:0.8177437941232615\n",
      "Epoch 4 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f97db8c2dea42b497bc276ccad396c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.29838141798973083 train acc 0.7576513830442637\n",
      "epoch 4 batch id 201 loss 0.3813175857067108 train acc 0.7740381515561819\n",
      "epoch 4 batch id 401 loss 0.16632629930973053 train acc 0.7885339507444363\n",
      "epoch 4 train acc 0.7947791605278831\n",
      "\n",
      "Epoch 4 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11e9e10269e435fac7dc9fef0d84010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.453336238861084 validation acc 0.8182310770256752\n",
      "epoch 4 validation acc 0.8262913741223671 \n",
      "정확도:0.8262913741223671, 정밀도:0.8270963640788046, 재현율:0.8262913741223671 f1 score:0.8259642749931195\n",
      "Epoch 5 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4a717eac744897a8dc74cc64606a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.08617322891950607 train acc 0.7948663721527712\n",
      "epoch 5 batch id 201 loss 0.2578222453594208 train acc 0.8071375686989207\n",
      "epoch 5 batch id 401 loss 0.18414272367954254 train acc 0.817894146201425\n",
      "epoch 5 train acc 0.8226638663364785\n",
      "\n",
      "Epoch 5 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eee85c1aad6476eace4b79ffd56c7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.5426966547966003 validation acc 0.826295045045045\n",
      "epoch 5 validation acc 0.8302657973921765 \n",
      "정확도:0.8302657973921765, 정밀도:0.8307668178219086, 재현율:0.8302657973921765 f1 score:0.8298278408317781\n",
      "Epoch 6 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce2b908947840fb9eeacbb2846cb154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.05722228065133095 train acc 0.8227287255043273\n",
      "epoch 6 batch id 201 loss 0.3236885070800781 train acc 0.8320289611241001\n",
      "epoch 6 batch id 401 loss 0.19883236289024353 train acc 0.8405456636910066\n",
      "epoch 6 train acc 0.8445189805962195\n",
      "\n",
      "Epoch 6 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01bb88b066a45ee8a1cb3ccf208d9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.7782596349716187 validation acc 0.8301872621670339\n",
      "epoch 6 validation acc 0.8332915412905383 \n",
      "정확도:0.8332915412905383, 정밀도:0.8335818056702204, 재현율:0.8332915412905383 f1 score:0.8330168493011992\n",
      "Epoch 7 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61af59ea76fa42ed8720e4d816958187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.06888030469417572 train acc 0.8445657283125294\n",
      "epoch 7 batch id 201 loss 0.21005572378635406 train acc 0.8520291770695648\n",
      "epoch 7 batch id 401 loss 0.08304362744092941 train acc 0.8590270419680287\n",
      "epoch 7 train acc 0.8623285432162897\n",
      "\n",
      "Epoch 7 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3fa2b044a34c4787ccbdd58e05056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.644648015499115 validation acc 0.8332637729549248\n",
      "epoch 7 validation acc 0.8359363805702823 \n",
      "정확도:0.8359363805702823, 정밀도:0.8360428363441731, 재현율:0.8359363805702823 f1 score:0.8356845510418192\n",
      "Epoch 8 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484b9b6d4409403aaeac41ab90f88175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.02716492861509323 train acc 0.8623679886825057\n",
      "epoch 8 batch id 201 loss 0.11714343726634979 train acc 0.8686756629730154\n",
      "epoch 8 batch id 401 loss 0.04565916210412979 train acc 0.8744994396937796\n",
      "epoch 8 train acc 0.8771903702078305\n",
      "\n",
      "Epoch 8 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376c7d6f420946639a5cf1d82b2e1f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.6697889566421509 validation acc 0.8359095463002719\n",
      "epoch 8 validation acc 0.8386879388164493 \n",
      "정확도:0.8386879388164493, 정밀도:0.8386985470857297, 재현율:0.8386879388164493 f1 score:0.8384185283169544\n",
      "Epoch 9 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99941082531e4e1185b72919785eb573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.0164454635232687 train acc 0.8772172427841675\n",
      "epoch 9 batch id 201 loss 0.030409766361117363 train acc 0.8823301202661972\n",
      "epoch 9 batch id 401 loss 0.01502185594290495 train acc 0.8871585633313396\n",
      "epoch 9 train acc 0.889390440564385\n",
      "\n",
      "Epoch 9 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b3451ba44841f9ad9b7b6cfc1846c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.6355103254318237 validation acc 0.8386930110220441\n",
      "epoch 9 validation acc 0.841106653293213 \n",
      "정확도:0.841106653293213, 정밀도:0.8411075797974195, 재현율:0.841106653293213 f1 score:0.8408644217958614\n",
      "Epoch 10 Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853f007205414db59949b5ace2e4392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.0023728571832180023 train acc 0.8894150912516149\n",
      "epoch 10 batch id 201 loss 0.013896630145609379 train acc 0.8937037666723339\n",
      "epoch 10 batch id 401 loss 0.012134980410337448 train acc 0.897692575765811\n",
      "epoch 10 train acc 0.8995548728879973\n",
      "\n",
      "Epoch 10 Validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ed99d8116e417d93e244155a37d401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.6052495241165161 validation acc 0.8411090079055784\n",
      "epoch 10 validation acc 0.8430792377131394 \n",
      "정확도:0.8430792377131394, 정밀도:0.8430942202971989, 재현율:0.8430792377131394 f1 score:0.8428533669597097\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "x_true = []\n",
    "x_pred = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "train_history=[]\n",
    "validation_history=[]\n",
    "loss_history=[]\n",
    "validation_loss_history=[]\n",
    "for e in range(num_epochs):\n",
    "    # epoch별 모델 저장할 폴더 생성\n",
    "    MODEL_PATH = PATH + f'epoch{e+1}/'\n",
    "    os.mkdir(MODEL_PATH)\n",
    "    \n",
    "#     train_acc = 0.0\n",
    "#     val_acc = 0.0\n",
    "    train_acc = 0\n",
    "    val_acc = 0\n",
    "    model.train()\n",
    "    print(f\"Epoch {e+1} Train\")\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        x_true.extend(label.cpu().detach().numpy().tolist())\n",
    "        x_pred.extend(torch.argmax(out, dim=1).cpu().detach().tolist())\n",
    "        # print(label.shape,out.shape)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "#         train_acc += calc_accuracy(out, label)\n",
    "        train_acc = accuracy_score(x_true, x_pred)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc))\n",
    "#             print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "#     train_history.append(train_acc / (batch_id+1))\n",
    "    train_history.append(train_acc)\n",
    "    loss_history.append(loss.data.cpu().numpy())\n",
    "#     print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc))\n",
    "    print()\n",
    "#     train_history.append(train_acc / (batch_id+1))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    #         test_loss = 0\n",
    "        print(f\"Epoch {e+1} Validation\")\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(validation_dataloader)):\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length= valid_length\n",
    "            label = label.long().to(device)\n",
    "            y_true.extend(label.cpu().detach().numpy().tolist())    # 정답 y_true 리스트에 cpu로 저장\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "#             print(f\"y_true : {label}\")\n",
    "#             print(f\"y_true : {out}\")\n",
    "            y_pred.extend(torch.argmax(out, dim=1).cpu().detach().tolist())    # 예측값 클래스별 가중치 y_pred 리스트에 cpu로 저장\n",
    "\n",
    "            loss = loss_fn(out, label)\n",
    "#             val_acc += calc_accuracy(out, label)\n",
    "            val_acc = accuracy_score(y_true, y_pred)\n",
    "            if batch_id % log_interval == 0:\n",
    "#                 print(\"epoch {} batch id {} loss {} validation acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), val_acc / (batch_id+1)))\n",
    "                print(\"epoch {} batch id {} loss {} validation acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), val_acc))\n",
    "#         validation_history.append(val_acc / (batch_id+1))\n",
    "        validation_history.append(val_acc)\n",
    "        validation_loss_history.append(loss.data.cpu().numpy())\n",
    "\n",
    "    #         val_loss += loss_fn(out, label).data.cpu().numpy()\n",
    "\n",
    "#         print(\"epoch {} validation acc {} \".format(e+1, val_acc / (batch_id+1)))\n",
    "        print(\"epoch {} validation acc {} \".format(e+1, val_acc))\n",
    "    #         validation_history.append(val_acc / (batch_id+1))\n",
    "\n",
    "        get_clf_eval(y_true, y_pred)\n",
    "\n",
    "        # 학습 모델 저장\n",
    "        torch.save(model, MODEL_PATH + 'Model.pt')  # 전체 모델 저장\n",
    "#         torch.save(model.state_dict(), MODEL_PATH + 'Model_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-O3GDGPwa--1"
   },
   "outputs": [],
   "source": [
    "# 직접 만든 새로운 문장으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Gr9elPd_bEdc"
   },
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"중립이\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"행복이\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"분노가\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"혐오가\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"공포가\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"놀람이\")\n",
    "\n",
    "\n",
    "\n",
    "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "nAD3RoYTbIBk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 : 오늘 마지막 시험을 쳤다.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 피곤하지만 이제 다 끝났다 생각하니깐 기분이 좋다.\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 동기들이랑 시험 끝나고 닭한마리도 먹고, 카페에서 팀플도 했다.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 제발 오류나지 말고 잘 되었으면 좋겠다.\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 엔터 쓰면 안 된다.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 구두점을 잘 찍으면 좋다!\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 버그가 발견돼서 슬프다.\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 새로 업데이트가 되었다니 너무 기쁘네요!\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 내 나무가 사라졌었어요ㅠ\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 근데 이유를 모르겠어요,,,드디어 주말이네용.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 행복한 주말을 보내야겠어요!\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 내 나무가 사라졌었어요.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 그래서 슬펐어요.\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 슬픈 감정 포인트를 받고 싶었는데 중립으로 떠서 또 우울했어요.\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 디비를 삭제하고 다시 써요.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 드디어 주말이네용.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 행복한 주말을 보내요.\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 하지만 해야할것들을 생각하면 막막하다\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 졸려\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 어렸을  때 외국 드라마에서나 봤던 모습이 재현되는 기분이다.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 하지만 또 취업준비를 생각하니 막막하고 슬프다.\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 놀랍고 무섭다.\n",
      ">> 입력하신 내용에서 공포가 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 후덜덜.\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 따로 감사 인사나 안부를 묻고 전하고 싶지만 선뜻 실천이 안된다\n",
      ">> 입력하신 내용에서 분노가 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 나이 먹으니 이것저것 괜한 노파심이 많아져서 그런듯 하다 갈수록 말 한마디 하는게 조심스런 시절이다\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 회원가입부터  시작할때 문제 많음\n",
      ">> 입력하신 내용에서 공포가 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 이제 제발 버그가 안 나왔으면 좋겠다.\n",
      ">> 입력하신 내용에서 분노가 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 최악이네요.\n",
      ">> 입력하신 내용에서 혐오가 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 다들 개발하느라 고생이 많아요.\n",
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 우와 신난다\n",
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 아빠 대장내시경 받는날  성가병원 기다리는중 ᆢ 세시\n",
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 따로 감사 인사나 안부를 묻고 전하고 싶지만 선뜻 실천이 안된다\n",
      ">> 입력하신 내용에서 분노가 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m :\n\u001b[0;32m----> 4\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m하고싶은 말을 입력해주세요 : \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m :\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SH/lib/python3.8/site-packages/ipykernel/kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SH/lib/python3.8/site-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 질문 무한반복하기! 0 입력시 종료\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == \"0\" :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of sentiment_analysis.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
